{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Library yang digunakan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers # type: ignore\n",
    "from tensorflow.keras.layers import Dropout # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n",
    "from keras.models import load_model # type: ignore\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 798 audio files with shape (798, 128, 128)\n",
      "Files loaded:\n",
      "['1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '2.mp3' '3.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3'\n",
      " '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3'\n",
      " '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3'\n",
      " '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3'\n",
      " '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3'\n",
      " '5.mp3' '6.mp3' '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3'\n",
      " '7.mp3' '1.mp3' '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3' '1.mp3'\n",
      " '2.mp3' '3.mp3' '4.mp3' '5.mp3' '6.mp3' '7.mp3']\n"
     ]
    }
   ],
   "source": [
    "def load_audio_files(root_path, n_mels=128, fixed_length=128):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for ayat_dir in dirs:\n",
    "            ayat_path = os.path.join(root, ayat_dir)\n",
    "            for file in os.listdir(ayat_path):\n",
    "                if file.endswith(\".mp3\"):\n",
    "                    file_path = os.path.join(ayat_path, file)\n",
    "                    try:\n",
    "                        # Memuat file audio\n",
    "                        y, sr = librosa.load(file_path, sr=None)\n",
    "                        # Mengonversi ke Mel-spectrogram\n",
    "                        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "                        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "                        # Menormalkan dimensi Mel-spectrogram ke fixed_length\n",
    "                        if S_dB.shape[1] < fixed_length:\n",
    "                            S_dB = np.pad(S_dB, ((0, 0), (0, fixed_length - S_dB.shape[1])), mode='constant')\n",
    "                        elif S_dB.shape[1] > fixed_length:\n",
    "                            S_dB = S_dB[:, :fixed_length]\n",
    "                        data.append(S_dB)\n",
    "                        labels.append(file)  # Gunakan nama file sebagai label\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Path ke direktori dataset Anda (Surah Al-Fatihah)\n",
    "data_path = r'D:\\Kuliah\\S6\\Studi Independen\\project akhir\\Bacaan Quran\\Surah Al-Fatihah'\n",
    "\n",
    "# Memuat dan mengonversi file audio ke Mel-spectrogram dengan dimensi tetap\n",
    "data, labels = load_audio_files(data_path, n_mels=128, fixed_length=128)\n",
    "\n",
    "# Debugging: Memastikan bentuk data sesuai dengan yang diharapkan\n",
    "if len(data.shape) == 3:\n",
    "    print(f\"Loaded {data.shape[0]} audio files with shape {data.shape}\")\n",
    "else:\n",
    "    print(\"No audio files were loaded correctly.\")\n",
    "\n",
    "# Menampilkan file yang berhasil dimuat\n",
    "print(\"Files loaded:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Standarisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistik standarisasi:\n",
      "Mean setiap fitur: [-4.112571e-07 -2.879771e-07 -2.372235e-07 ... -3.686077e-08 -3.686077e-08\n",
      " -3.686077e-08]\n",
      "Deviasi standar setiap fitur: [0.9999993  1.000001   1.0000007  ... 0.99999905 0.99999905 0.99999905]\n"
     ]
    }
   ],
   "source": [
    "# Standarisasi data\n",
    "scaler = StandardScaler()\n",
    "data_flat = np.reshape(data, (data.shape[0], -1))\n",
    "scaled_data = scaler.fit_transform(data_flat)\n",
    "\n",
    "# Menampilkan statistik standarisasi\n",
    "print(\"Statistik standarisasi:\")\n",
    "print(f\"Mean setiap fitur: {scaled_data.mean(axis=0)}\")\n",
    "print(f\"Deviasi standar setiap fitur: {scaled_data.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Memisahkan Data Training dan Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 128, 128) (638, 128, 128) (160, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(data.shape, X_train.shape, X_test.shape,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Membuat Data Latih Menggunakan Algoritma CNN + Membuat model evaluasi untuk mengukur tingkat akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.1529 - loss: 47.4934 - val_accuracy: 0.1562 - val_loss: 5.8952\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 796ms/step - accuracy: 0.3233 - loss: 5.7277 - val_accuracy: 0.5063 - val_loss: 5.0703\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 762ms/step - accuracy: 0.5388 - loss: 4.9727 - val_accuracy: 0.4125 - val_loss: 5.4929\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 667ms/step - accuracy: 0.5806 - loss: 4.6865 - val_accuracy: 0.6500 - val_loss: 4.1700\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 673ms/step - accuracy: 0.6816 - loss: 4.0094 - val_accuracy: 0.6000 - val_loss: 4.0122\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 653ms/step - accuracy: 0.6406 - loss: 3.7648 - val_accuracy: 0.6375 - val_loss: 3.6664\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 629ms/step - accuracy: 0.7162 - loss: 3.5019 - val_accuracy: 0.7000 - val_loss: 3.3695\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 607ms/step - accuracy: 0.7614 - loss: 3.1946 - val_accuracy: 0.7188 - val_loss: 3.0986\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 707ms/step - accuracy: 0.7561 - loss: 2.9828 - val_accuracy: 0.7188 - val_loss: 2.9475\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 716ms/step - accuracy: 0.7600 - loss: 2.7885 - val_accuracy: 0.7312 - val_loss: 2.8192\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 777ms/step - accuracy: 0.7846 - loss: 2.5909 - val_accuracy: 0.7125 - val_loss: 2.7399\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 677ms/step - accuracy: 0.7779 - loss: 2.5137 - val_accuracy: 0.7375 - val_loss: 2.6324\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 632ms/step - accuracy: 0.8204 - loss: 2.3375 - val_accuracy: 0.7063 - val_loss: 2.5278\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 709ms/step - accuracy: 0.8146 - loss: 2.2944 - val_accuracy: 0.6938 - val_loss: 2.4267\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 747ms/step - accuracy: 0.7931 - loss: 2.1807 - val_accuracy: 0.7000 - val_loss: 2.3379\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 627ms/step - accuracy: 0.8290 - loss: 2.0239 - val_accuracy: 0.6438 - val_loss: 2.4418\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 722ms/step - accuracy: 0.7763 - loss: 2.0454 - val_accuracy: 0.6750 - val_loss: 2.2204\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 764ms/step - accuracy: 0.7843 - loss: 1.9539 - val_accuracy: 0.7063 - val_loss: 2.1935\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 774ms/step - accuracy: 0.7969 - loss: 1.8773 - val_accuracy: 0.7500 - val_loss: 1.9804\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 774ms/step - accuracy: 0.8371 - loss: 1.6859 - val_accuracy: 0.7812 - val_loss: 1.9460\n",
      "5/5 - 1s - 174ms/step - accuracy: 0.7812 - loss: 1.9460\n",
      "\n",
      "Test accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "# Resize data ke (128, 128) dan reshape ke (n_samples, 128, 128, 1)\n",
    "resized_X_train = np.array([resize(x, (128, 128)) for x in X_train])\n",
    "resized_X_train = resized_X_train.reshape((resized_X_train.shape[0], 128, 128, 1))\n",
    "\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform y_test\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Build the CNN model with Dropout and Regularization\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define Early Stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train_encoded, epochs=20, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan raw string untuk path dan format .keras yang disarankan\n",
    "model.save(r'D:\\Kuliah\\S6\\Studi Independen\\project akhir\\Bacaan Quran\\Sahabat_Quran.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1.mp3, Predicted Ayat: 1.mp3, True Ayat: 1.mp3\n",
      "Prediksi benar\n",
      "File: 2.mp3, Predicted Ayat: 3.mp3, True Ayat: 2.mp3\n",
      "Prediksi salah\n",
      "File: 3.mp3, Predicted Ayat: 3.mp3, True Ayat: 3.mp3\n",
      "Prediksi benar\n",
      "File: 4.mp3, Predicted Ayat: 4.mp3, True Ayat: 4.mp3\n",
      "Prediksi benar\n",
      "File: 5.mp3, Predicted Ayat: 5.mp3, True Ayat: 5.mp3\n",
      "Prediksi benar\n",
      "File: 6.mp3, Predicted Ayat: 2.mp3, True Ayat: 6.mp3\n",
      "Prediksi salah\n",
      "File: 7.mp3, Predicted Ayat: 3.mp3, True Ayat: 7.mp3\n",
      "Prediksi salah\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memuat file audio dan mengonversi ke Mel-spectrogram\n",
    "def load_audio_files(root_path, n_mels=128, fixed_length=128):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for ayat_dir in dirs:\n",
    "            ayat_path = os.path.join(root, ayat_dir)\n",
    "            for file in os.listdir(ayat_path):\n",
    "                if file.endswith(\".mp3\"):\n",
    "                    file_path = os.path.join(ayat_path, file)\n",
    "                    try:\n",
    "                        y, sr = librosa.load(file_path, sr=None)\n",
    "                        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "                        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "                        if S_dB.shape[1] < fixed_length:\n",
    "                            S_dB = np.pad(S_dB, ((0, 0), (0, fixed_length - S_dB.shape[1])), mode='constant')\n",
    "                        elif S_dB.shape[1] > fixed_length:\n",
    "                            S_dB = S_dB[:, :fixed_length]\n",
    "                        data.append(S_dB)\n",
    "                        labels.append(file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Path ke data baru untuk prediksi\n",
    "new_data_path = r'D:\\Kuliah\\S6\\Studi Independen\\project akhir\\aset lainnya\\G'\n",
    "\n",
    "# Memuat dan mengonversi file audio baru ke Mel-spectrogram\n",
    "new_data, new_labels = load_audio_files(new_data_path, n_mels=128, fixed_length=128)\n",
    "new_data = new_data.reshape((new_data.shape[0], 128, 128, 1))\n",
    "\n",
    "# Memuat model yang telah dilatih\n",
    "model = load_model(r'D:\\Kuliah\\S6\\Studi Independen\\project akhir\\Bacaan Quran\\Sahabat_Quran.keras', compile=False)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Definisikan fungsi prediksi di luar loop\n",
    "@tf.function\n",
    "def predict(model, data):\n",
    "    return model(data)\n",
    "\n",
    "# Melakukan prediksi\n",
    "new_predictions = predict(model, new_data)\n",
    "new_predictions = np.argmax(new_predictions, axis=1)\n",
    "\n",
    "# Gunakan LabelEncoder yang sama\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)  # Pastikan ini sesuai dengan y_train yang digunakan selama pelatihan\n",
    "\n",
    "# Transformasi prediksi dan true labels\n",
    "new_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "# Pastikan true_labels sesuai dengan format yang diharapkan\n",
    "true_labels = ['1.mp3', '2.mp3', '3.mp3', '4.mp3', '5.mp3', '6.mp3', '7.mp3']  # Sesuaikan dengan data Anda\n",
    "\n",
    "for file, pred, true in zip(new_labels, new_predictions, true_labels):\n",
    "    print(f\"File: {file}, Predicted Ayat: {pred}, True Ayat: {true}\")\n",
    "    if pred == true:\n",
    "        print(\"Prediksi benar\")\n",
    "    else:\n",
    "        print(\"Prediksi salah\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
